#spark settings
spark_ui_port = 4040

#Â storage params
s3_ssl_enabled = false
s3_endpoint = "http://127.0.0.1:8000"
s3_path_style_access = true
checkpoint_path = /spark_checkpoint

# read from environment vars
aws_access_key_id = "accessKey1"
aws_secret_access_key = "verySecretKey1"

# locations
bucket_name = "METADATA"
bucket_landing_path = /landing
bucket_staging_path = /staging

##############
# Query Exec #
##############
# cache settings
cache_dataframes = false
landing_cache_expiry = 30 seconds
spark_sql_print_explain = true

############
# Pipeline #
############

# pipeline settings
trigger_time = 10 seconds
# this is the maxOpIndex number for an interval
compaction_record_interval = 10

# kafka settings
kafka_bootstrap_servers = "localhost:9092"
kafka_topic = "backbeat"

#############
# Compactor #
#############

# compaction
landing_purge_tolerance = 10 seconds


# graphite params
graphite {
  hostname = "" // turns search metrics off
  port = 2003
}
